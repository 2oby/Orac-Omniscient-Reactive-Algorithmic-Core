version: "3.9"

services:
  ollama:
    image: dustynv/ollama:0.6.8-r36.4
    container_name: orac-ollama
    command: sh -c "mkdir -p /data/logs && ollama serve > /data/logs/ollama.log 2>&1 & sleep 5 && touch /data/logs/ollama.log && tail -f /data/logs/ollama.log"
    ports:
      - "11434:11434"
    volumes:
      - ./models/gguf:/models/gguf
      - ./logs:/logs
    environment:
      - OLLAMA_MODELS=/models/gguf
      # Optimize for Jetson Orin Nano (adjust based on your specific model)
      - CUDA_VISIBLE_DEVICES=0
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:11434/api/version || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - orac-network

  orac:
    build: .
    container_name: orac
    volumes:
      - ./models/gguf:/models/gguf:ro
      - ./logs:/app/logs
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      - OLLAMA_HOST=orac-ollama
      - OLLAMA_PORT=11434
      - LOG_LEVEL=INFO
      - LOG_DIR=/app/logs
    restart: unless-stopped
    networks:
      - orac-network

networks:
  orac-network:
    name: orac-network
