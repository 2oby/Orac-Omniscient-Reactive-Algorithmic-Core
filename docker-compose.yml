version: "3.9"

services:
  ollama:
    image: dustynv/ollama:r36.4.3
    container_name: orac-ollama
    command: sh -c "ollama serve & tail -f /data/logs/ollama.log"
    ports:
      - "11434:11434"
    volumes:
      - ./models/gguf:/models/gguf
      - ./logs:/logs
    environment:
      - OLLAMA_MODELS=/models/gguf
      # Optimize for Jetson Orin Nano (adjust based on your specific model)
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - orac-network

  orac:
    build: .
    container_name: orac
    volumes:
      - ./models/gguf:/models/gguf:ro
      - ./logs:/app/logs
    depends_on:
      - ollama
    environment:
      - OLLAMA_HOST=orac-ollama
      - OLLAMA_PORT=11434
      - LOG_LEVEL=INFO
      - LOG_DIR=/app/logs
    restart: unless-stopped
    networks:
      - orac-network

networks:
  orac-network:
    name: orac-network
