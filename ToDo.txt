The project is well-organized, with a clear separation of concerns (e.g., orac/llama_cpp_client.py, data/ for configs, models/gguf for Qwen3 0.6B, and FastAPI-related files like orac/api.py). The goal is to enhance the project with a configuration system for Home Assistant integration, using a single data/grammars.yaml file that includes generic constraints (e.g., "bedroom lights", "turn on", "bedroom") for the LLM’s JSON output and mappings to specific Home Assistant entity IDs and services for post-processing. The configuration will be dynamically populated by fetching devices, actions, and locations from Home Assistant’s API, with support for manual edits via a web UI. The system will ensure backwards compatibility with the existing JSON grammar, use generic terms to simplify the LLM’s task, and maintain performance (<0.2s overhead) on the Jetson Orin Nano.
Step-by-Step Guide
Step 1: Define the Configuration Structure
Modified: Update the existing data/grammars.yaml file to include Home Assistant configuration, with sections for generic constraints (home_automation_constraints) and mappings (mapping) alongside the JSON grammar.

Structure grammars.yaml to support:
Generic devices (e.g., "bedroom lights", "kitchen switch") for LLM output.

Actions (e.g., "turn on", "bright") with synonyms (e.g., "activate" for "turn on") and parameters (e.g., brightness_pct: 70 for lights).

Generic locations (e.g., "bedroom", "kitchen").

Mappings from generic terms to specific Home Assistant entity IDs (e.g., "bedroom lights" → ["light.bedroom_lamp_1", "light.bedroom_ceiling"]) and services (e.g., "turn on" → light.turn_on).

Domain-specific mappings for actions (e.g., "bright" → brightness_pct: 70 for lights, "warm" → temperature: 25 for climate).

A default error response (e.g., {"error": "Invalid command or device"}) for invalid inputs.

Ensure the config supports manual additions (e.g., custom devices) and auto-discovered entities without overwriting manual entries.

New: Store all Home Assistant configuration (constraints and mappings) in data/grammars.yaml, dynamically populated via Home Assistant API or user GUI, eliminating the need for a separate home_assistant_config.yaml file.

Step 2: Implement Auto-Discovery of Devices and Locations
At service startup, query Home Assistant’s REST API (/api/states) to fetch all entities (e.g., light.bedroom_light, climate.bedroom_heating).

Group entities into generic devices (e.g., light.bedroom_light, light.bedroom_ceiling → "bedroom lights") and locations (e.g., area_id: area_bedroom → "bedroom") based on entity ID naming conventions or area metadata from /api/areas.

Modified: Append discovered generic devices, actions, and locations to the home_automation_constraints section of data/grammars.yaml, and populate the mapping section with specific entity IDs (e.g., "bedroom lights": ["light.bedroom_lamp_1", "light.bedroom_ceiling"]) and services (e.g., "turn on": ["light.turn_on", "switch.turn_on"]).

Preserve manually added devices, locations, and mappings in grammars.yaml, ensuring they are not overwritten during auto-discovery.

Store the updated configuration in data/grammars.yaml as the local cache.

Step 3: Generate a Dynamic JSON Grammar
At service startup, read the home_automation_constraints section of data/grammars.yaml to extract generic devices (e.g., "bedroom lights"), actions (e.g., "turn on"), and locations (e.g., "bedroom").

Modified: Update the JSON grammar in data/grammars.yaml by dynamically modifying the string rule to constrain device, action, and location to the generic terms from home_automation_constraints (e.g., device ::= "bedroom lights" | "kitchen switch" | ...).

Ensure the grammar enforces outputs like {"device": str, "action": str, "location": str} with only permitted generic values.

Save the grammar in memory for use by orac/llama_cpp_client.py during inference.

Update the grammar whenever grammars.yaml changes (e.g., via web UI edits or auto-discovery).

Modified: Ensure the JSON grammar in data/grammars.yaml remains backwards compatible with the existing definition, allowing non-home-automation JSON outputs to function as before.

Step 4: Process User Commands with the Model
Accept raw user input (e.g., “turn on the bedroom light”, “brighten the lounge lamp”) via an API endpoint in orac/api.py.

Pass the input to orac/llama_cpp_client.py with the Qwen3 0.6B model in JSON mode, using the dynamic grammar from data/grammars.yaml.

Ensure the model outputs structured JSON (e.g., {"device": "bedroom lights", "action": "turn on", "location": "bedroom"}), constrained to generic terms to reduce inconsistencies.

Step 5: Post-Process Model Outputs
Read the model’s JSON output and map it to Home Assistant’s REST API format: {"domain": str, "service": str, "entity_id": list, "parameters": dict} using the mapping section in data/grammars.yaml.

Modified: Use the mapping section to convert generic terms to specific entity IDs and services (e.g., "bedroom lights" → ["light.bedroom_lamp_1", "light.bedroom_ceiling"], "turn on" → light.turn_on).

Handle inconsistencies in the output (e.g., {"device": "bedroom light"} → {"device": "bedroom lights"}) using the synonyms in home_automation_constraints.

Apply domain-specific mappings for actions based on the device’s domain:
Lights: bright → brightness_pct: 70, dim → brightness_pct: 20, warm → color_temp: 250 (mireds).

Speakers/TV: loud → volume_level: 0.7, soft → volume_level: 0.3.

Underfloor Heating: warm → temperature: 25, hot → temperature: 28.

Blinds: 50%_open → position: 50.

Return the default error response (e.g., {"error": "Invalid command or device"}) if the output cannot be mapped.

Log errors to logs/ using orac.logger.

Step 6: Send Commands to Home Assistant
Use the post-processed JSON to send a REST API request to Home Assistant (e.g., POST /api/services/light/turn_on with payload {"entity_id": ["light.bedroom_lamp_1", "light.bedroom_ceiling"], "brightness_pct": 70}).

Handle API responses, logging successes and errors to logs/.

Return the API response or error to the user via the API endpoint.

Step 7: Develop a Web UI for Configuration Management
Extend orac/api.py to include FastAPI endpoints for:
Viewing the current grammars.yaml configuration.

Adding/editing generic devices, actions, locations, synonyms, and mappings.

Processing user commands (e.g., “turn on the bedroom light”).

Save UI changes to data/grammars.yaml, triggering updates to the grammar and mappings.

Host the UI at http://jetson-ip:8000/docs for easy access.

Step 8: Optimize for Performance
Cache the grammars.yaml config, mappings, and grammar in memory to avoid disk reads during command processing.

Use dictionary-based lookups for post-processing to keep overhead <0.05s.

Leverage ORIN_NANO_OPTIMIZATIONS in orac/llama_cpp_client.py for fast inference (~0.08–0.12s with Qwen3 0.6B).

Ensure total processing time (inference + post-processing + API call) stays <0.2s.

Minimize memory usage (<1MB for config and mappings) to fit within the Jetson’s 8GB.

Step 9: Deploy and Test
Update the existing Dockerfile and docker-compose.yml in the project root to include dependencies (e.g., pyyaml, pydantic, fastapi, uvicorn, aiohttp).

Mount /Models and /Models/config (mapped to data/) in the Docker container.

Use the NVIDIA Container Toolkit for GPU acceleration.

Test the service with sample commands (e.g., “brighten the lounge lamp”, “make the bedroom heating warm”).

Verify auto-discovery appends entities correctly and preserves manual entries in grammars.yaml.

Test the web UI for config edits and command processing.

Step 10: Document and Maintain
Update README.md with setup instructions, API endpoints, and examples.

Add tests in tests/ to validate auto-discovery, grammar generation, post-processing, and API calls.

Monitor logs in logs/ for debugging.

Periodically re-run auto-discovery to catch new Home Assistant entities.

Integration with Existing Project
Config File: Use data/grammars.yaml for both the JSON grammar and Home Assistant configuration (constraints and mappings), dynamically updated via API or UI.

Modules: Add new files to orac/:
config_manager.py: Handle loading, validation, and auto-discovery for grammars.yaml.

grammar_generator.py: Generate dynamic grammar from home_automation_constraints.

synonym_processor.py: Post-process model outputs using mappings and synonyms.

ha_client.py: Manage Home Assistant API calls.

API: Extend orac/api.py for web UI endpoints.

Inference: Use existing orac/llama_cpp_client.py for Qwen3 inference.

Tests: Add test cases to tests/ for new functionality.

Scripts: Update scripts/deploy_and_test.sh to include config initialization and UI startup.

Logs: Store logs in logs/ using orac.logger.

Why This Approach
Single Config File: Storing Home Assistant constraints and mappings in grammars.yaml simplifies configuration management and aligns with the grammar used by the LLM.

Generic Constraints: Using intuitive terms (e.g., "bedroom lights") reduces the LLM’s complexity and improves output consistency.

Post-Processing: Mapping generic terms to specific entity IDs and services in post-processing ensures Home Assistant compatibility without burdening the LLM.

Backwards Compatibility: The JSON grammar remains unchanged, ensuring existing systems work.

Auto-Discovery: Dynamically populates grammars.yaml with Home Assistant data, preserving manual entries.

Web UI: Simplifies config management for non-technical users.

Performance: Keeps processing <0.2s using in-memory caching and GPU acceleration.

Scalability: Supports grouping entities (e.g., multiple lights as "bedroom lights") and future expansions.

Immediate Tasks
Fix favoriting functionality in the UI (implemented with validation)

Set Qwen3 1.7B as the default model

Optimize Orin GPU performance:
Enable maximum power mode

Profile GPU utilization

Adjust CUDA/GPU layers settings

Test with different batch sizes

New: Implement auto-discovery to populate home_automation_constraints and mapping sections in data/grammars.yaml using Home Assistant API (/api/states, /api/areas, /api/services).

New: Update grammar_generator.py to dynamically modify the JSON grammar’s string rule based on home_automation_constraints from grammars.yaml.

New: Implement post-processing in synonym_processor.py to map generic LLM outputs to Home Assistant entity IDs and services using the mapping section.

Future Tasks
Add model performance benchmarks

Create test suite for JSON command parsing

Document model configurations and parameters

Add model-specific error handling

Implement model fallback strategy

Resource Monitoring:
Monitor server resource usage (CPU, GPU, memory)

Dynamically adjust parameters based on system load

Integrate with psutil for memory monitoring

Implement adaptive resource management

ORAC - Completed Implementation
High-Level Approach for API-Compatible of orac.llama_cpp_client
Completed Implementation
 Preserve All Public Method Signatures
Kept generate(), list_models(), start_server(), and quantize_model() exactly as they are

All parameters, return types, and method names stay identical

External callers don’t need any changes

 Internal Server Management
Added private methods for server lifecycle management

Maintains internal state tracking current model and server status

Handles all server lifecycle management transparently

 Smart Server Reuse Strategy
Checks if server is already running with correct model

Uses existing server via HTTP API if available

Transparently starts new server if needed

Caches server instances per model

 Backward Compatible start_server() Method
Kept existing method signature and return type

Returns wrapper object that mimics subprocess.Popen

Tracks internal server state

 Lazy Initialization Pattern
No servers started in __init__()

Servers only start when generate() is first called

Maintains lightweight initialization behavior

 Transparent Error Handling
Converts HTTP errors back to same exception types/messages

Maintains same timeout behavior and error messages

External code sees no difference in error handling

 Resource Management Strategy
Uses __del__() and weak references to clean up servers

Handles multiple LlamaCppClient instances gracefully

Maintains stateless appearance

 Session Management
Creates aiohttp sessions lazily and reuses them

Cleans up sessions automatically

Handles session errors gracefully

Benefits Achieved
Zero Breaking Changes: Existing code continues to work unchanged

Performance Gains: Internal efficiency improvements without API disruption

Gradual Migration: Added new optional methods for advanced server control

Risk Mitigation: Persistent server approach working well, with CLI approach as fallback

Model Configuration Tasks
Completed
Configured TinyLlama 1.1B for JSON command parsing:
System prompt with example I/O format

Parameters: temp=0.05, top_p=0.1, top_k=5, max_tokens=50

Configured Qwen3 0.6B for JSON command parsing:
System prompt with /no_think directive

Parameters: temp=0.1, top_p=0.9, top_k=40, max_tokens=50

Implemented persistent server model with automatic management

Added server reuse strategy with caching

Implemented lazy initialization pattern

Added transparent error handling

Implemented session management with aiohttp

Implemented model selection and settings UI

Added support for model settings persistence

Implemented default model configuration

Added startup model pre-loading

Development Environment Details
Connection Information
Development Machine IP: http://192.168.1.13

SSH Connection: ssh orin

Working Directory: /home/toby/ORAC

Log File System
Log Directory: /home/toby/ORAC/logs/

Current Log Files:
orac.log (current)

orac.log.1 (previous)

orac.log.2 (older)

